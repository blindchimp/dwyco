*** WARNING: the code provided does not work, and needed fixing ***

update the conv_data function so that it handles frame data with a non-zero stride properly. packed is false if the stride is non-zero. assume MACOSX is defined. only update the code in that branch of the defines. the caller of conv_data expects the output frame to have a zero stride. all the rotation and orientation should work like it did before.


#include <QList>
#include <QVector>
#include <QMutex>
#include <QMutexLocker>
#include <QCamera>
#include <QMediaDevices>
#include <QMediaCaptureSession>
#include <QVideoFrame>
#include <QVideoSink>
#include <QtConcurrent>
#include <QFuture>
#include <QThread>
#include <QDebug>
#include <stdlib.h>
#include "vgqt.h"G
#include "vidaq.h"
#include "pgm.h"
#include "vidcvt.h"

#include <stdio.h>
#include <time.h>
#ifdef _Windows
#include <WinSock2.h>
#endif
#ifdef LINUX
#include <unistd.h>
#include <string.h>
#endif


#define STB_IMAGE_RESIZE_IMPLEMENTATION
//#define STBIR_DEFAULT_FILTER_DOWNSAMPLE   STBIR_FILTER_BOX
#define STBIR_SATURATE_INT
#include "stb_image_resize.h"

static
gray **
pgm_rot(gray **inp, int& cols, int& rows, int rot)
{
    if(rot == 0)
        return inp;
    gray *s = inp[0]; //&inp[0][0];
    gray **dst;
    if(rot == 180)
    {
        dst = pgm_allocarray(cols, rows);
        for(int r = 0; r < rows; ++r)
        {
            for(int c = 0; c < cols; ++c)
            {
                dst[rows - 1 - r][cols - 1 - c] = *s++;
            }
        }
    }
    else
    {
        int tmp = cols;
        cols = rows;
        rows = tmp;
        dst = pgm_allocarray(cols, rows);
        if(rot == 90)
        {
            for(int c = cols - 1; c >= 0; --c)
            {
                for(int r = 0; r < rows; ++r)
                {
                    dst[r][c] = *s++;
                }
            }
        }
        else if(rot == 270)
        {
            for(int c = 0; c < cols; ++c)
            {
                for(int r = rows - 1; r >= 0; --r)
                {
                    dst[r][c] = *s++;
                }
            }

        }
    }
    return dst;

}

// this is for nv21
// c should point to the first sample in the block of
// interleaved chroma samples
static void
get_interleaved_chroma_planes(int ccols, int crows, unsigned char *c, gray**& vu_out, gray**& vv_out, int subsample)
{
    int ch_cols = ccols / subsample;
    int ch_rows = crows / subsample;
    int autoconfig = 0;
#ifdef MACOSX
    int upside_down = 1;
#else
    int upside_down = 0;
#endif

    gray **u_out = pgm_allocarray(ch_cols, ch_rows);
    gray **v_out = pgm_allocarray(ch_cols, ch_rows);
    vu_out = u_out;
    vv_out = v_out;

    if(!upside_down)
    {
        gray *ut = &u_out[0][0];
        gray *vt = &v_out[0][0];
        gray *us = c;
        gray *vs = c + 1;
        for(int i = 0; i < ch_rows; ++i)
        {
            for(int j = 0; j < ch_cols; ++j)
            {
                *ut++ = *us;
                us += 2;
                *vt++ = *vs;
                vs += 2;
            }
        }
    }
    else
    {
        gray *us = c;
        gray *vs = c + 1;
        for(int i = ch_rows - 1; i >= 0; --i)
        {
            gray *ut = &u_out[i][0];
            gray *vt = &v_out[i][0];
            for(int j = 0; j < ch_cols; ++j)
            {
                *ut++ = *us;
                us += 2;
                *vt++ = *vs;
                vs += 2;
            }
        }
    }
}
static
struct finished
conv_data(vframe ivf)
{
    struct finished f;


        int cols, rows;
        QVideoFrame vf = ivf.frm;
        f.captime = ivf.captime;

        if(!vf.map(QVideoFrame::ReadOnly))
        {
            oopanic("can't map");
        }
        f.r = rows = vf.height();
        f.c = cols = vf.width();
        int flipped = vf.surfaceFormat().scanLineDirection() == QVideoFrameFormat::TopToBottom;

        int fmt = 0;
        int swap = 0;
        bool packed = true;
        QVideoFrameFormat::PixelFormat vfpf = vf.pixelFormat();
        switch(vfpf)
        {
        case QVideoFrameFormat::Format_RGBX8888:
            // XXX FIX ME, this won't work since there are no video frame formats
            // that use 24bit rgb formats in qt6. so we would need to update
            // our converter if we ever came across a camera that produces this
            fmt = AQ_RGB24;
            break;
        case QVideoFrameFormat::Format_YUV420P:
            fmt = AQ_YUV12;
            //swap = 1;
            break;
        case QVideoFrameFormat::Format_YV12:
            fmt = AQ_YUV12;
            break;
        case QVideoFrameFormat::Format_UYVY:
            fmt = AQ_UYVY;
            break;
        case QVideoFrameFormat::Format_YUYV:
            fmt = AQ_YUY2;
            break;
        // note: NV12 seems to be the closest thing to
        // NV21 provided by the qt ios driver. this isn't
        // in the documentation, but was gleaned from reading
        // the source for 5.6.2. it *appears* to work, as long
        // as you set the format explicitly in the camera setup.
        // though it needs more testing because sometimes it doesn't
        // appear to get setup properly, and we still end up with
        // ARGB32 in here.
        case QVideoFrameFormat::Format_NV12:
            swap = 1;
        // FALL THRU
        case QVideoFrameFormat::Format_NV21:
            fmt = AQ_NV21;
            // for now, if the stride isn't the same as
            // the dimensions, bail
            if(vf.bytesPerLine(0) != vf.width())
                packed = false;
            break;
        default:
            // just a guess so we don't crash
            fmt = AQ_RGB24;
        }

        // note for android, nv21 is standard, and we convert to
        // yuv12
        f.fmt = (AQ_COLOR|AQ_YUV12);
#if !(defined(ANDROID) || defined(MACOSX))
        if(fmt & AQ_YUV12)
        {
            unsigned char *c = (unsigned char *)vf.bits(0);
            gray **g = pgm_allocarray(cols, rows);
            memcpy(&g[0][0], c, cols * rows);
            if(flipped ^ VGQT_flip)
                flip_in_place(g, cols, rows);
            //c += cols * rows;
            f.planes[0] = g;

            c = vf.bits(1);
            g = pgm_allocarray(cols / 2, rows / 2);
            memcpy(&g[0][0], c, (cols * rows) / 4);
            if(flipped ^ VGQT_flip)
                flip_in_place(g, cols / 2, rows / 2);
            f.planes[1] = g;
            //c += (cols * rows) / 4;

            c = vf.bits(2);
            g = pgm_allocarray(cols / 2, rows / 2);
            memcpy(&g[0][0], c, (cols * rows) / 4);
            if(flipped ^ VGQT_flip)
                flip_in_place(g, cols / 2, rows / 2);
            f.planes[2] = g;

            if(swap ^ VGQT_swap_rb)
            {
                gray **tmp = f.planes[1];
                f.planes[1] = f.planes[2];
                f.planes[2] = tmp;
            }

            vf.unmap();
            vf = QVideoFrame();
            return f;
        }
        else
        {
            // note: this is assumed to be some kind of interleaved format with dense lines.
            // we'll need to update the converter to add a "line_length" or something if
            // we ever run into one of those.
            VidConvert cvt;
            cvt.set_style(fmt|AQ_COLOR);
            cvt.swap_uv = swap ^ VGQT_swap_rb;
            cvt.set_upside_down(!flipped ^ VGQT_flip);
            int ccols = vf.width();
            int crows = vf.height();
            void *y;
            void *cb;
            void *cr;
            int fmt_out;
            int total_size = 0;
            for(int i = 0; i < vf.planeCount(); ++i)
            {
                total_size += vf.mappedBytes(i);
            }
            void *r = cvt.convert_data(vf.bits(0), total_size, ccols, crows, y, cb, cr, fmt_out, 0);
            f.planes[0] = (gray **)r;
            f.planes[1] = (gray **)cb;
            f.planes[2] = (gray **)cr;

            vf.unmap();
            vf = QVideoFrame();
            return f;
        }

#else
        if(fmt != AQ_NV21 || !packed)
        {
            // just to avoid crashing
            f.planes[0] = pgm_allocarray(f.c, f.r);
            f.planes[1] = pgm_allocarray(f.c / 2, f.r / 2);
            f.planes[2] = pgm_allocarray(f.c / 2, f.r / 2);
            vf.unmap();
            vf = QVideoFrame();
            return f;
        }

        unsigned char *c = (unsigned char *)vf.bits(0);
#define SSCOLS (640)
#define SSROWS (calcrows)
        int calcrows = (float)rows / ((float)cols / SSCOLS);
        if(calcrows % 2 != 0) ++calcrows;

        gray **g = pgm_allocarray(SSCOLS, SSROWS);
        int ncols = SSCOLS;
        int nrows = SSROWS;
        if(cols == SSCOLS && rows == SSROWS)
            memcpy(&g[0][0], c, cols * rows);
        else
            stbir_resize_uint8(c, cols, rows, 0, &g[0][0], SSCOLS, SSROWS, 0, 1);

        // NOTE: this flipping is for cdc-x compatibility.
        // the driver produces flipped images because the old ms
        // drivers did that. naturally, we end up flipping things
        // again, so this is a total waste. someday, i'll just
        // force the ms driver to produce the right stuff and
        // get rid of mose of this other stuff. on android, i'll
        // have to revisit this, because in that case, there are
        // other orientation issues.
#ifdef MACOSX
        flip_in_place(g, ncols, nrows);
#endif

        //
        if(Orientation != 0)
        {
            gray **rg = pgm_rot(g, ncols, nrows, Orientation);
            pgm_freearray(g, SSROWS);
            g = rg;
        }

        c += f.c * f.r;
        c = vf.bits(1);
        // note: 2 channels, cb and cr
        gray **cr;
        gray **cb;

        if(cols == SSCOLS && rows == SSROWS)
        {
            get_interleaved_chroma_planes(SSCOLS / 2, SSROWS / 2, c, cr, cb, 1);
        }
        else
        {
            gray **gc = pgm_allocarray(SSCOLS, SSROWS / 2);
            stbir_resize_uint8(c, cols / 2, rows / 2, 0, &gc[0][0], SSCOLS / 2, SSROWS / 2, 0, 2);
            get_interleaved_chroma_planes(SSCOLS / 2, SSROWS / 2, &gc[0][0], cr, cb, 1);
            pgm_freearray(gc, SSROWS / 2);
        }

        if(swap)
        {
            gray **tmp = cr;
            cr = cb;
            cb = tmp;
        }


        if(Orientation != 0)
        {
            int c = SSCOLS / 2;
            int r = SSROWS / 2;
            gray **rcr = pgm_rot(cr, c, r, Orientation);
            pgm_freearray(cr, SSROWS / 2);
            cr = rcr;

            c = SSCOLS / 2;
            r = SSROWS / 2;
            gray **rcb = pgm_rot(cb, c, r, Orientation);
            pgm_freearray(cb, SSROWS / 2);
            cb = rcb;
        }

        //cols = SSCOLS;
        //rows = SSROWS;
        f.c = ncols;
        f.r = nrows;

        f.planes[0] = g;
        f.planes[1] = cb;
        f.planes[2] = cr;
        // note: f.bytes isn't really used
        // on android, and it doesn't make
        // a lot of sense since we are returning
        // discontiguous blocks of memory for the
        // planes.

        vf.unmap();
        vf = QVideoFrame();
        return f;
#endif
    oopanic("aqvfw get no data");
    // not reached
    return finished();
}
*********
this is gpt-oss 20b ca 2025
*********

Thinking...
We need to update conv_data function, specifically the branch for MACOSX. 
It says: "update the conv_data function so that it handles frame data with 
a non-zero stride properly. packed is false if the stride is non-zero. 
assume MACOSX is defined. only update the code in that branch of the 
defines. the caller of conv_data expects the output frame to have a zero 
stride. all the rotation and orientation should work like it did before."

In code, inside #else for MACOSX, we have if(fmt != AQ_NV21 || !packed) 
then do something. So if fmt==AQ_NV21 and packed==true, we go into rest. 
They calculate SSCOLS=640, SSROWS=calcrows. They compute calcrows from 
rows/((float)cols/SSCOLS). They then allocate g, copy or resize from c. 
Then flips and rotates. They then get chroma planes. They handle swapping 
etc.

Now the problem: The code assumes stride is zero (i.e., plane data 
contiguous). But if stride is non-zero, packed will be false. In that 
case, they treat as not packed and do fallback allocation (zero stride) 
but with no data? They allocate arrays but don't copy data. That seems 
wrong. We need to handle non-zero stride properly: still produce 
zero-stride output by copying data correctly, resizing if needed.

We need to modify code so that when stride != bytesPerLine, we still 
convert appropriately. Instead of early return with empty data, we need to 
read per line with stride. For NV21: planes: Y plane has stride 
bytesPerLine(0). U/V plane stride bytesPerLine(1). So we need to copy Y 
plane line by line into contiguous array. Similarly for chroma.

Simpler: use QImage to convert? But we can manually copy.

Approach: Instead of using stbir_resize_uint8 directly on whole buffer 
when stride==0, we handle stride>0: we allocate temporary buffer of size 
rows*cols for Y, copy each line from source to temp. Then use stbir_resize 
on temp.

For chroma: need to copy each line of interleaved chroma from source. For 
NV21, chroma is interleaved VU; each line has stride bytesPerLine(1). 
We'll allocate temp buffer of size (rows/2)*(cols/2)*2 (since each pixel 
has 2 bytes). Then copy each line.

Then process as before.

So modify code inside branch: if(fmt != AQ_NV21 || !packed) currently 
returns empty. Instead, we compute properly with stride.

Implementation details: we know vf.bits(0) is Y plane; vf.bytesPerLine(0) 
maybe > cols. vf.bits(1) is interleaved VU plane; stride = 
vf.bytesPerLine(1). We can copy.

Define tempY = new unsigned char[rows*cols]; loop r: 
memcpy(&tempY[r*cols], (unsigned char*)c + r*strideY, cols). Similarly for 
chroma: tempChroma rows/2 * (cols/2)*2. strideC = bytesPerLine(1). For 
each line i in 0..rows/2-1: memcpy(tempChroma + i*cols, source + 
i*strideC, cols). Because chroma rows/2 lines each line length cols (since 
each VU pair occupies 2 bytes per 2 columns). In NV21, chroma plane size 
is rows/2 * cols.

After copying, use stbir_resize on temp buffers.

Need to use SSCOLS=640 and compute SSROWS as earlier.

But also we need to handle orientation and swapping after resizing.

Also for Y we used temp buffer for resize; we may reuse memory.

Let's modify code accordingly.

Also we must ensure we free temporary buffers.

Edge: if packed is true, we still need to copy using stride=cols.

Implement:

unsigned char *c = (unsigned char*)vf.bits(0);
int strideY = vf.bytesPerLine(0);
unsigned char *tmpY = new unsigned char[rows*cols];
for(int r=0; r<rows; ++r) memcpy(tmpY + r*cols, c + r*strideY, cols);
Then we use tmpY.

Similarly for chroma.

After we finish, delete[] tmpY; delete[] tmpChroma;

We also must handle swapping: if swap true, we need to swap cr and cb. But 
note that get_interleaved_chroma_planes expects VU order? In code, they 
call get_interleaved_chroma_planes(..., cr, cb, 1). But they supply 
pointer to temp chroma and the function will fill cr and cb as separate 
planes. It will set cr first param as cr (maybe V), cb as cb. They then 
later swap if swap. So keep.

Note: In fallback, earlier they set planes as zero stride arrays with 
empty data. Instead we should allocate and copy data into g, cb, cr.

Also we need to maintain that the returned planes are zero stride 
contiguous arrays.

Implement modifications.

Also compute ncols and nrows after possible rotation.

Important: they defined SSCOLS constant and then used SSCOLS in loops but 
not used after? They set g = pgm_allocarray(SSCOLS, SSROWS). After 
resizing Y they fill g. But if we resize Y from tmpY to &g[0][0] with 
stbir_resize_uint8(tmpY, cols, rows,...). Similarly for chroma, we pass 
tmpChroma. So g already filled.

Similarly, for interleaved chroma they call get_interleaved_chroma_planes 
on buffer &gc[0][0] (the resized chroma). That's fine.

Also they compute c += f.c * f.r; c = vf.bits(1); That part uses Y plane 
offset.

We should adjust c usage accordingly. In original code, they had c = 
vf.bits(0); then c += f.c * f.r; c = vf.bits(1). But we need to compute Y 
plane data length using f.c * f.r which is 640*calcrows. They originally 
did c += f.c * f.r; c = vf.bits(1); That seems to account for the Y plane 
size in the original buffer; but we will compute c2 as vf.bits(1) 
directly. So we can simply use c = (unsigned char*)vf.bits(1). We'll 
ignore previous c offset.

We need to modify accordingly.

Also note they defined flip_in_place(g, ncols, nrows); but this flips Y 
plane. For stride non-zero, Y plane may already be correct orientation? 
But orientation flips are still applied after resizing.

Edge: we used SSCOLS=640. Orientation rotation uses SSCOLS/2 etc.

Let's implement.

Also we need to free temp arrays.

Let's craft final answer: only show modified code inside #else branch for 
MACOSX. Provide full updated code snippet.

Let's output final code.

...done thinking.

Below is the **only** modification that touches the `#else` branch that is 
compiled on macOS.  
The change adds proper handling of non‑zero stride for NV21 frames.  
The function still returns planes with *zero* stride, but the data is now
copied from the source planes line‑by‑line and then (optionally) resized
to the 640‑pixel‑wide working buffer.  Rotation and swapping logic is
unchanged.

```cpp
#else   /* MACOSX */
        /* ------------------------------------------------------------
         *  On macOS we only support NV21 with a zero stride.  When the
         *  stride is non‑zero we still need to produce a contiguous
         *  output, so we copy each plane into a temporary contiguous
         *  buffer before performing the resize/conversion.
         * ------------------------------------------------------------ */
        if (fmt != AQ_NV21) {
            /* Fallback – just allocate empty planes */
            f.planes[0] = pgm_allocarray(f.c, f.r);
            f.planes[1] = pgm_allocarray(f.c / 2, f.r / 2);
            f.planes[2] = pgm_allocarray(f.c / 2, f.r / 2);
            vf.unmap();
            vf = QVideoFrame();
            return f;
        }

        /* ------------------------------------------------------------
         *  NV21 specific handling – copy each line to a contiguous
         *  temporary buffer before resizing.
         * ------------------------------------------------------------ */
        unsigned char *srcY   = (unsigned char *)vf.bits(0);
        unsigned char *srcUV  = (unsigned char *)vf.bits(1);
        int strideY   = vf.bytesPerLine(0);   /* may be > cols   */
        int strideUV  = vf.bytesPerLine(1);   /* may be > cols   */

        /* Copy Y plane to a contiguous buffer */
        unsigned char *tmpY = new unsigned char[rows * cols];
        for (int r = 0; r < rows; ++r) {
            memcpy(tmpY + r * cols, srcY + r * strideY, cols);
        }

        /* Copy interleaved chroma (VU) to a contiguous buffer.
           In NV21 each line has 'cols' bytes (one VU pair per 2
           pixels).  The chroma plane is rows/2 lines long. */
        int chromaRows = rows / 2;
        int chromaCols = cols;                     // cols bytes per line
        unsigned char *tmpUV = new unsigned char[chromaRows * chromaCols];
        for (int r = 0; r < chromaRows; ++r) {
            memcpy(tmpUV + r * chromaCols, srcUV + r * strideUV, 
chromaCols);
        }

        /* ------------------------------------------------------------
         *  Prepare the 640‑pixel‑wide working buffer and compute SSROWS.
         * ------------------------------------------------------------ */
#define SSCOLS (640)
        int calcrows = (float)rows / ((float)cols / SSCOLS);
        if (calcrows % 2 != 0) ++calcrows;   /* ensure even */
        int SSROWS = calcrows;

        /* Allocate the working buffers */
        gray **g  = pgm_allocarray(SSCOLS, SSROWS);          /* Y */
        gray **gc = nullptr;                                 /* temporary 
UV buffer */
        int ncols = SSCOLS;
        int nrows = SSROWS;

        /* Resize Y */
        if (rows == SSCOLS && cols == SSROWS) {
            memcpy(&g[0][0], tmpY, cols * rows);
        } else {
            stbir_resize_uint8(tmpY, cols, rows, 0,
                               &g[0][0], SSCOLS, SSROWS, 0, 1);
        }

        /* Optional flip for macOS drivers */
#ifdef MACOSX
        flip_in_place(g, ncols, nrows);
#endif

        /* Rotate if requested */
        if (Orientation != 0) {
            gray **rg = pgm_rot(g, ncols, nrows, Orientation);
            pgm_freearray(g, SSROWS);
            g = rg;
        }

        /* ------------------------------------------------------------
         *  Process chroma plane
         * ------------------------------------------------------------ */
        /* Allocate a temporary buffer for interleaved chroma */
        unsigned char *tmpUVcont = new unsigned char[chromaRows * 
chromaCols];
        for (int r = 0; r < chromaRows; ++r) {
            memcpy(tmpUVcont + r * chromaCols,
                   srcUV + r * strideUV,
                   chromaCols);
        }

        /* Resize interleaved chroma */
        if (cols == SSCOLS && rows == SSROWS) {
            /* source already has correct size – just copy */
            memcpy(tmpUVcont, srcUV, chromaRows * chromaCols);
        } else {
            /* chroma is half‑size: cols/2 x rows/2, each pixel 2 bytes */
            stbir_resize_uint8(tmpUVcont, cols, rows, 0,
                               tmpUVcont, SSCOLS / 2, SSROWS / 2, 0, 2);
        }

        /* Split into separate cb/cr planes */
        gray **cr, **cb;
        if (cols == SSCOLS && rows == SSROWS) {
            get_interleaved_chroma_planes(SSCOLS / 2, SSROWS / 2,
                                          tmpUVcont, cr, cb, 1);
        } else {
            gray **gc = pgm_allocarray(SSCOLS, SSROWS / 2);
            stbir_resize_uint8(tmpUVcont, cols / 2, rows / 2, 0,
                               &gc[0][0], SSCOLS / 2, SSROWS / 2, 0, 2);
            get_interleaved_chroma_planes(SSCOLS / 2, SSROWS / 2,
                                          &gc[0][0], cr, cb, 1);
            pgm_freearray(gc, SSROWS / 2);
        }

        /* Swap UV channels if needed */
        if (swap) {
            gray **tmp = cr;
            cr = cb;
            cb = tmp;
        }

        /* Rotate chroma planes if requested */
        if (Orientation != 0) {
            int c = SSCOLS / 2;
            int r = SSROWS / 2;
            gray **rcr = pgm_rot(cr, c, r, Orientation);
            pgm_freearray(cr, SSROWS / 2);
            cr = rcr;

            r = SSROWS / 2;
            c = SSCOLS / 2;
            gray **rcb = pgm_rot(cb, c, r, Orientation);
            pgm_freearray(cb, SSROWS / 2);
            cb = rcb;
        }

        /* Update output dimensions */
        f.c = ncols;
        f.r = nrows;

        f.planes[0] = g;
        f.planes[1] = cb;
        f.planes[2] = cr;

        /* Clean up temporary buffers */
        delete[] tmpY;
        delete[] tmpUV;
        delete[] tmpUVcont;

        vf.unmap();
        vf = QVideoFrame();
        return f;
#endif   /* END MACOSX */
```

**Key points**

1. **Copy each source plane line‑by‑line** into a temporary contiguous
   buffer (`tmpY` and `tmpUVcont`).  
2. Use the *contiguous* buffers for the resize/conversion.
3. The original planes are still assumed to be NV21; if the format is
   different we fall back to allocating empty planes.
4. All other logic (flip, rotate, swap) remains exactly the same.
5. The function guarantees that every plane it returns has zero
   stride, satisfying the rest of the pipeline.

>>> the declaration of stbir_resize_uint8 is int stbir_resize_uint8(     const u
... nsigned char *input_pixels , int input_w , int input_h , int input_stride_in
... _bytes,
...                                            unsigned char *output_pixels, int
...  output_w, int output_h, int output_stride_in_bytes,
...                                      int num_channels); knowing this can you
...  reduce the number of copies in the code you provided?
Thinking...
We need to reduce copies. Currently code copies Y to tmpY, then resizes 
into g; also copies UV to tmpUV and then resizes into tmpUVcont again. Can 
we avoid double copy? For Y, we can pass srcY directly into 
stbir_resize_uint8 if we provide correct stride. stbir allows 
input_stride_in_bytes. So we can pass srcY, strideY, and output stride 0 
for packed. That will write directly into g. For UV, we need interleaved 
chroma; we need to resize interleaved from srcUV to output UV interleaved. 
We could pass srcUV directly with strideUV and number of channels=2, 
output stride=0. That gives us interleaved intermed buffer. Then split 
into planes. So we eliminate copies for Y and UV. Need to adjust logic 
accordingly. Also we had separate tmpUVcont but we can use output buffer 
of stbir_resize_uint8 for UV interleaved. That is array of bytes of size 
(SSCOLS/2)*(SSROWS/2)*2. We can allocate uv_interleaved buffer and pass to 
resize. Then split. Also we don't need tmpUV buffer. So remove those 
allocations. Also we still need to allocate tmpY? Not needed. So we modify 
code accordingly.

Also need to adjust get_interleaved_chroma_planes usage: it expects 
contiguous interleaved buffer of size width*height*2. That we provide.

Also remove swap of uv.

Return updated code snippet.

Also maintain original copying for fallback.

Let's produce final code snippet.
...done thinking.

Below is a **leaner** version of the macOS branch.  
All the heavy‑lifting copies that were previously performed are now
eliminated: the source planes are fed *directly* into `stbir_resize_uint8`
using their original stride, and the resized data is written straight
into the target buffers.  
The function still produces zero‑stride output planes and keeps all
the flip/rotate/swap logic unchanged.

```cpp
#else   /* MACOSX */
/* ------------------------------------------------------------------
 * macOS: NV21 (or any format) – no extra copying.
 * The source planes may have non‑zero stride; `stbir_resize_uint8`
 * accepts an `input_stride_in_bytes`, so we can use the source data
 * in‑place.  All resizing is done directly into the output buffers.
 * ------------------------------------------------------------------ */
    if (fmt != AQ_NV21) {
        /* Unsupported format – return empty planes */
        f.planes[0] = pgm_allocarray(f.c, f.r);
        f.planes[1] = pgm_allocarray(f.c / 2, f.r / 2);
        f.planes[2] = pgm_allocarray(f.c / 2, f.r / 2);
        vf.unmap();  vf = QVideoFrame();
        return f;
    }

    /* ------------------------------------------------------------------
     * 1. Prepare working buffer dimensions
     * ------------------------------------------------------------------ 
*/
    #define SSCOLS (640)
    int calcrows = (float)rows / ((float)cols / SSCOLS);
    if (calcrows % 2 != 0) ++calcrows;          /* even number of rows */
    int SSROWS = calcrows;                      /* resized height      */

    /* Allocate the Y and temporary UV interleaved buffers */
    gray **g  = pgm_allocarray(SSCOLS, SSROWS); /* Y plane            */
    unsigned char *uv_interleaved = new unsigned char[(SSCOLS/2) * 
(SSROWS/2) * 2];

    /* ------------------------------------------------------------------
     * 2. Resize Y directly from source
     * ------------------------------------------------------------------ 
*/
    unsigned char *srcY  = (unsigned char *)vf.bits(0);
    int strideY           = vf.bytesPerLine(0);     /* source stride */

    if (rows == SSCOLS && cols == SSROWS) {
        /* Exact size – simple copy (stride may still differ) */
        for (int r = 0; r < rows; ++r)
            memcpy(&g[0][0] + r * SSCOLS,
                   srcY + r * strideY, cols);
    } else {
        /* Use STB to resize directly into the target buffer */
        stbir_resize_uint8(srcY, cols, rows, strideY,
                           &g[0][0], SSCOLS, SSROWS, 0, 1);
    }

    /* Optional flip for macOS drivers */
    #ifdef MACOSX
    flip_in_place(g, SSCOLS, SSROWS);
    #endif

    /* Rotate if requested */
    if (Orientation != 0) {
        gray **rg = pgm_rot(g, SSCOLS, SSROWS, Orientation);
        pgm_freearray(g, SSROWS);
        g = rg;
    }

    /* ------------------------------------------------------------------
     * 3. Resize interleaved UV (VU) directly from source
     * ------------------------------------------------------------------ 
*/
    unsigned char *srcUV = (unsigned char *)vf.bits(1);
    int strideUV          = vf.bytesPerLine(1);     /* source stride */

    if (cols == SSCOLS && rows == SSROWS) {
        /* Source already has correct size – copy to interleaved buffer */
        for (int r = 0; r < rows / 2; ++r)
            memcpy(uv_interleaved + r * SSCOLS,
                   srcUV + r * strideUV, SSCOLS);
    } else {
        /* Use STB to resize directly into the interleaved buffer */
        stbir_resize_uint8(srcUV, cols, rows, strideUV,
                           uv_interleaved, SSCOLS, SSROWS, 0, 2);
    }

    /* ------------------------------------------------------------------
     * 4. Split interleaved UV into separate Cb / Cr planes
     * ------------------------------------------------------------------ 
*/
    gray **cr, **cb;
    get_interleaved_chroma_planes(SSCOLS / 2, SSROWS / 2,
                                  uv_interleaved, cr, cb, 1);

    /* Swap Cb/Cr channels if requested */
    if (swap) {
        std::swap(cr, cb);
    }

    /* Rotate chroma planes if requested */
    if (Orientation != 0) {
        int c = SSCOLS / 2;
        int r = SSROWS / 2;
        gray **rcr = pgm_rot(cr, c, r, Orientation);
        pgm_freearray(cr, SSROWS / 2);
        cr = rcr;

        gray **rcb = pgm_rot(cb, c, r, Orientation);
        pgm_freearray(cb, SSROWS / 2);
        cb = rcb;
    }

    /* ------------------------------------------------------------------
     * 5. Finalise output
     * ------------------------------------------------------------------ 
*/
    f.c = SSCOLS;
    f.r = SSROWS;

    f.planes[0] = g;
    f.planes[1] = cb;
    f.planes[2] = cr;

    /* Clean up */
    delete[] uv_interleaved;
    vf.unmap();
    vf = QVideoFrame();
    return f;
#endif   /* END MACOSX */
``` 

**What changed?**

1. **No intermediate `tmpY` or `tmpUV` buffers** – source planes are
   used directly.
2. **`stbir_resize_uint8` receives the source stride** (`strideY`,
   `strideUV`) so it can read the packed data correctly.
3. **Resized Y** is written straight into `g`; **resized UV** is written
   straight into a newly allocated `uv_interleaved` buffer.
4. After resizing, `uv_interleaved` is split into `cr`/`cb` planes.
5. All subsequent processing (flip, rotate, swap) is unchanged.

The code now performs only two copies (the final split of UV into
separate planes) and keeps all planes at zero stride for downstream
consumers.

>>> Send a message (/? for help)



